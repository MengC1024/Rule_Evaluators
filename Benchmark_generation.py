import argparse
from collections import defaultdict
import json
import random
from typing import List
from concurrent.futures import ThreadPoolExecutor, as_completed
from openai import OpenAI
import re
import time
from tqdm import tqdm
from prompt import prompt_generate_issue


class RuleGeneration:
    def __init__(
        self,
        model: str,
        base_url: str,
        api_key: str,
        max_workers: int = 4,
        temperature: float = 0.3,
        timeout: int = 30,
        max_retries: int = 3,
        retry_delay: int = 5,
        task_config_path: str = "task_config.json",
    ):
        """
        åˆå§‹åŒ–è§„åˆ™ç”Ÿæˆç±»
        
        :param model: æ¨¡å‹åç§°
        :param base_url: API base URL
        :param api_key: API key
        :param max_workers: å¹¶è¡Œå¤„ç†çš„æœ€å¤§çº¿ç¨‹æ•°
        :param temperature: æ¸©åº¦å‚æ•°
        :param timeout: æ¯æ¬¡è¯·æ±‚çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        :param max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        :param retry_delay: é‡è¯•é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰
        :param task_config_path: ä»»åŠ¡é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.client = OpenAI(base_url=base_url, api_key=api_key)
        self.model = model
        self.max_workers = max_workers
        self.temperature = temperature
        self.timeout = timeout
        self.max_retries = max_retries
        self.retry_delay = retry_delay

        # è¯»å–ä»»åŠ¡é…ç½®
        with open(task_config_path, 'r') as f:
            self.task_config = json.load(f)

    def _safe_request_with_retry(self, prompt: str, label_types: list):
        """
        å¸¦é‡è¯•æœºåˆ¶çš„å®‰å…¨è¯·æ±‚æ–¹æ³•
        
        :param prompt: æç¤ºè¯
        :param label_types: å…è®¸çš„æ ‡ç­¾ç±»å‹åˆ—è¡¨
        :return: è§£æåçš„ç»“æœåˆ—è¡¨
        """
        last_error = None
        for attempt in range(1, self.max_retries + 1):
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=self.temperature,
                    seed=1031,
                    timeout=self.timeout,
                )
                result = response.choices[0].message.content.strip()
                
                try:
                    # å…ˆå°è¯•å®šä½ ```json
                    if "```json" in result:
                        result = result.split("```json")[1].split("```")[0].strip()
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ° ```jsonï¼Œåˆ™å®šä½åˆ° [ ]
                    elif "[" in result and "]" in result:
                        result = result.split("[")[1].split("]")[0].strip()
                    else:
                        raise ValueError("æ— æ³•æ‰¾åˆ°åˆé€‚çš„ JSON æ ¼å¼")
                    
                    # å°è¯•è§£æä¸º JSON
                    result_dict = json.loads(result)
                except json.JSONDecodeError as e:
                    raise ValueError(f"è¿”å›å†…å®¹ä¸æ˜¯åˆæ³• JSONï¼š{e}\nå†…å®¹ï¼š{result[:100]}")

                # æ£€æŸ¥ç»“æ„æ˜¯å¦ç¬¦åˆ
                if not isinstance(result_dict, list):
                    raise ValueError(f"é¡¶å±‚ç»“æ„åº”ä¸ºåˆ—è¡¨ï¼Œä½†å®é™…æ˜¯ {type(result_dict).__name__}")

                for i, item in enumerate(result_dict):
                    if not isinstance(item, dict):
                        raise ValueError(f"ç¬¬ {i} ä¸ªå…ƒç´ ä¸æ˜¯å­—å…¸ï¼š{item}")

                    # æ£€æŸ¥å¿…é¡»å­—æ®µ
                    missing_keys = [k for k in ["rule", "explanation", "label_type"] if k not in item]
                    if missing_keys:
                        raise ValueError(f"ç¬¬ {i} ä¸ªå…ƒç´ ç¼ºå°‘å­—æ®µï¼š{missing_keys}")

                    # æ£€æŸ¥ label_type æ˜¯å¦åœ¨æšä¸¾å€¼ä¸­
                    label = item["label_type"]
                    if label not in label_types:
                        raise ValueError(
                            f"ç¬¬ {i} ä¸ªå…ƒç´ çš„ label_type='{label}' ä¸åœ¨å…è®¸é›†åˆ {label_types}"
                        )
                return result_dict
                
            except Exception as e:
                last_error = e
                print(f"âš ï¸  ç¬¬ {attempt}/{self.max_retries} æ¬¡è¯·æ±‚å¤±è´¥ï¼š{e}")
                if attempt < self.max_retries:
                    time.sleep(self.retry_delay)
        
        # å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥
        raise Exception(f"è¯·æ±‚åœ¨é‡è¯• {self.max_retries} æ¬¡åä»å¤±è´¥: {last_error}")

    def _generate_llm_rule(self, description: str, official_rule: str):
        """
        ä½¿ç”¨ LLM ç”Ÿæˆè§„åˆ™
        
        :param description: æè¿°
        :param official_rule: å®˜æ–¹è§„åˆ™
        :return: æŒ‰é”™è¯¯ç±»å‹åˆ†ç»„çš„ç”Ÿæˆç»“æœ
        """
        output = {}

        for error_type, error_detail in self.task_config.items():
            try:
                examples_lines = [f"- {label}: {desc}" for label, desc in error_detail.items()]
                error_details_str = "\n".join(examples_lines)
                label_type_str = " | ".join(error_detail.keys())

                prompt = prompt_generate_issue.format(
                    description=description,
                    official_rule=official_rule,
                    error_type=error_type,
                    error_details=error_details_str,
                    label_type=label_type_str,
                )

                result_list = self._safe_request_with_retry(prompt, list(error_detail.keys()))
                output[error_type] = result_list

            except Exception as e:
                print(f"âš ï¸  ç”Ÿæˆ {error_type} å¤±è´¥ï¼š{e}")
                continue

        return output

    def generate_rule(self, item: dict):
        """ç”Ÿæˆå•ä¸ªè§„åˆ™"""
        description = item.get("description", "")
        official_rule = item.get("rule", "")
        return self._generate_llm_rule(description, official_rule)

    def generate_batch_rules(self, items: List[dict]):
        """æ‰¹é‡ç”Ÿæˆè§„åˆ™"""
        results = []
        indexed_items = [(index, item) for index, item in enumerate(items)]
        
        def generate_rules_for_item(index: int, item: dict):
            try:
                rule = self.generate_rule(item)
                return (index, rule)
            except Exception as e:
                return (index, f"Error: {str(e)}")
            
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = {
                executor.submit(generate_rules_for_item, index, item): (index, item) 
                for index, item in indexed_items
            }

            for f in tqdm(as_completed(futures), total=len(futures), desc="Generating Rules", ncols=100):
                index, result = f.result()
                # è·³è¿‡å®Œå…¨é”™è¯¯çš„é¡¹
                if isinstance(result, str) and result.startswith("Error:"):
                    print(f"âš ï¸  è·³è¿‡ç¬¬ {index} æ¡è§„åˆ™ï¼Œå› ç”Ÿæˆé”™è¯¯: {result}")
                    continue
                results.append((index, result))

        results.sort(key=lambda x: x[0])
        return [result for _, result in results]


def run_generation(
    model: str,
    base_url: str,
    api_key: str,
    rule_language: str,
    max_rules: int = None,
    max_workers: int = 200,
    temperature: float = 1.0,
    timeout: int = 960,
    max_retries: int = 3,
    retry_delay: int = 8,
):
    """
    è¿è¡Œè§„åˆ™ç”Ÿæˆå®éªŒ
    
    :param model: æ¨¡å‹åç§°
    :param base_url: API base URL
    :param api_key: API key
    :param rule_language: è§„åˆ™è¯­è¨€
    :param max_rules: æœ€å¤§å¤„ç†è§„åˆ™æ•°é‡ï¼ˆNoneè¡¨ç¤ºå¤„ç†å…¨éƒ¨ï¼‰
    :param max_workers: æœ€å¤§å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°
    :param temperature: æ¸©åº¦å‚æ•°
    :param timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´
    :param max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
    :param retry_delay: é‡è¯•å»¶è¿Ÿ
    """
    import os
    
    input_file = f"./dataset/{rule_language}_detections.json"
    output_file = f"./dataset/{rule_language}_detections_error.json"

    if not os.path.exists(input_file):
        raise FileNotFoundError(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {input_file}")

    with open(input_file, "r", encoding="utf-8") as f:
        rules_data = json.load(f)
    
    # é™åˆ¶å¤„ç†çš„è§„åˆ™æ•°é‡
    if max_rules is not None and max_rules > 0:
        original_count = len(rules_data)
        rules_data = rules_data[:max_rules]
        print(f"ğŸ“Š é™åˆ¶å¤„ç†è§„åˆ™æ•°é‡ï¼š{original_count} -> {len(rules_data)}")

    generator = RuleGeneration(
        model=model,
        base_url=base_url,
        api_key=api_key,
        max_workers=max_workers,
        temperature=temperature,
        timeout=timeout,
        max_retries=max_retries,
        retry_delay=retry_delay,
    )

    print(f"âœ… è¯»å–åˆ° {len(rules_data)} æ¡æ£€æµ‹è§„åˆ™ï¼Œå¼€å§‹ç”Ÿæˆ LLM_rule...\n")

    all_llm_rules = generator.generate_batch_rules(rules_data)

    result = defaultdict(list)

    for item, error_type_llm_rules in zip(rules_data, all_llm_rules):
        for error_type, llm_rules in error_type_llm_rules.items():
            for llm_rule in llm_rules:
                if (llm_rule.get("rule") is not None and 
                    llm_rule.get("explanation") is not None and 
                    llm_rule.get("label_type") is not None and 
                    llm_rule.get("rule") != item["rule"]):
                    result[error_type].append({
                        "generated_rule": llm_rule.get("rule"),
                        "explanation": llm_rule.get("explanation"),
                        "label_type": llm_rule.get("label_type"),
                        "description": item["description"],
                        "official_rule": item["rule"]
                    })

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(result, f, indent=4, ensure_ascii=False)

    print(f"\nâœ… å·²å®Œæˆæ‰€æœ‰è§„åˆ™ç”Ÿæˆï¼Œç»“æœå·²ä¿å­˜åˆ°ï¼š{output_file}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="è¿è¡Œè§„åˆ™ç”Ÿæˆå®éªŒ")
    
    # æ¨¡å‹é…ç½®å‚æ•°
    parser.add_argument("--model", type=str, required=True, help="æ¨¡å‹åç§°")
    parser.add_argument("--base_url", type=str, required=True, help="API base URL")
    parser.add_argument("--api_key", type=str, required=True, help="API key")
    
    # ä»»åŠ¡å‚æ•°
    parser.add_argument("--rule_language", type=str, required=True, help="è§„åˆ™è¯­è¨€ (å¦‚ en, zh)")
    parser.add_argument("--max_rules", type=int, default=None, help="æœ€å¤§å¤„ç†è§„åˆ™æ•°é‡ï¼ˆä¸æŒ‡å®šåˆ™å¤„ç†å…¨éƒ¨ï¼‰")
    
    # å¯é€‰å‚æ•°
    parser.add_argument("--max_workers", type=int, default=200, help="æœ€å¤§å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°")
    parser.add_argument("--temperature", type=float, default=1.0, help="æ¸©åº¦å‚æ•°")
    parser.add_argument("--timeout", type=int, default=960, help="è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰")
    parser.add_argument("--max_retries", type=int, default=3, help="æœ€å¤§é‡è¯•æ¬¡æ•°")
    parser.add_argument("--retry_delay", type=int, default=8, help="é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰")

    args = parser.parse_args()

    run_generation(
        model=args.model,
        base_url=args.base_url,
        api_key=args.api_key,
        rule_language=args.rule_language,
        max_rules=args.max_rules,
        max_workers=args.max_workers,
        temperature=args.temperature,
        timeout=args.timeout,
        max_retries=args.max_retries,
        retry_delay=args.retry_delay,
    )
